{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AFqtMujrYSI-"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import plotly as px\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmPcA4HfYSI_",
        "outputId": "0153fb20-5377-460f-ed10-1197afd82c7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3480 entries, 0 to 3479\n",
            "Data columns (total 7 columns):\n",
            " #   Column     Non-Null Count  Dtype  \n",
            "---  ------     --------------  -----  \n",
            " 0   Date       3480 non-null   object \n",
            " 1   Open       3480 non-null   float64\n",
            " 2   High       3480 non-null   float64\n",
            " 3   Low        3480 non-null   float64\n",
            " 4   Close      3480 non-null   float64\n",
            " 5   Adj Close  3480 non-null   float64\n",
            " 6   Volume     3480 non-null   int64  \n",
            "dtypes: float64(5), int64(1), object(1)\n",
            "memory usage: 190.4+ KB\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(r'/BTC-USD.csv')\n",
        "df_time = df.set_index('Date')\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zw9H9rH0YSI_"
      },
      "outputs": [],
      "source": [
        "df_time = df_time.reset_index()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n38Y8RXyYSI_"
      },
      "outputs": [],
      "source": [
        "# import plotly.express as px\n",
        "\n",
        "# fig = px.line(df, x='Date', y='Adj Close', title=\"BitCoin Adj closed price\")\n",
        "# fig.update_xaxes(\n",
        "#     rangeslider_visible=True,\n",
        "#     rangeselector=dict(\n",
        "#         buttons=list([\n",
        "#             dict(count=1, label=\"1m\", step=\"month\", stepmode=\"backward\"),\n",
        "#             dict(count=6, label=\"6m\", step=\"month\", stepmode=\"backward\"),\n",
        "#             dict(count=1, label=\"YTD\", step=\"year\", stepmode=\"todate\"),\n",
        "#             dict(count=1, label=\"1y\", step=\"year\", stepmode=\"backward\"),\n",
        "#             dict(step=\"all\")\n",
        "#         ])\n",
        "#     )\n",
        "# )\n",
        "# fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3v1NzOhYSI_"
      },
      "outputs": [],
      "source": [
        "def MACD(DF,a = 6,b= 13,c = 5):\n",
        "    df = DF.copy()\n",
        "    df['ma_fast'] = df['Adj Close'].ewm(span = a,min_periods = a).mean()\n",
        "    df['ma_slow'] = df['Adj Close'].ewm(span = b,min_periods = b).mean()\n",
        "    df['macd'] = df['ma_fast'] - df['ma_slow']\n",
        "    df['macd_signal'] = df['macd'].ewm(span = 9, min_periods =c).mean()\n",
        "    df = df.drop(columns = ['ma_fast', 'ma_slow', 'macd'] )\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JGn4ogiBYSJA"
      },
      "outputs": [],
      "source": [
        "df= MACD(df)\n",
        "df = df.set_index('Date')\n",
        "# df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r8aMAhuLYSJA"
      },
      "outputs": [],
      "source": [
        "# df[['macd_signal']].plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VyfQvkIjYSJA"
      },
      "outputs": [],
      "source": [
        "# df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sMm4FEERYSJA"
      },
      "outputs": [],
      "source": [
        "def ATR(Df, n =7):\n",
        "    df = Df.copy()\n",
        "    # ATR\n",
        "    df['C_H - C_L'] = df['High'] - df['Low']\n",
        "    df['C_H - P_C'] = df['High'] - df['Adj Close'].shift(1)\n",
        "    df['C_L - P_C'] = df['Low'] - df['Adj Close'].shift(1)\n",
        "    df['TR'] = df[['C_H - C_L', 'C_H - P_C', 'C_L - P_C']].max(axis = 1, skipna = False)\n",
        "    df['ATR'] = df['TR'].ewm(span = n, min_periods = n).mean()\n",
        "    df = df.drop(columns= ['C_H - C_L','C_H - P_C','C_L - P_C','TR'])\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ia07EqF8YSJA"
      },
      "outputs": [],
      "source": [
        "df = ATR(df)\n",
        "# df.head(15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zBsn1Q5YSJB"
      },
      "outputs": [],
      "source": [
        "# df[['ATR']].plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4THo2LhYSJB"
      },
      "outputs": [],
      "source": [
        "def BB(Df, n = 7):\n",
        "    df = Df.copy()\n",
        "    # BB\n",
        "    df['MB'] = df['Adj Close'].rolling(n).mean()\n",
        "    df['UB'] = df['MB'] + 2*df['Adj Close'].rolling(n).std(ddof = 0)\n",
        "    df['LB'] = df['MB'] - 2*df['Adj Close'].rolling(n).std(ddof = 0)\n",
        "    df['BB_width'] = df['UB'] - df['LB']\n",
        "\n",
        "\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-gbLUTUYSJB"
      },
      "outputs": [],
      "source": [
        "df = BB(df)\n",
        "# import plotly.graph_objects as go\n",
        "\n",
        "# # Assuming df_final is your DataFrame\n",
        "# # Create a Plotly figure\n",
        "# fig = go.Figure()\n",
        "\n",
        "# # Add traces for 'Appliances' and 'App_Pred\n",
        "\n",
        "# fig.add_trace(go.Scatter(x=df.index, y=df['Adj Close'], mode='lines', name='actual curve'))\n",
        "# fig.add_trace(go.Scatter(x=df.index, y=df['MB'], mode='lines', name='MB'))\n",
        "# fig.add_trace(go.Scatter(x=df.index, y=df['UB'], mode='lines', name='UB'))\n",
        "# fig.add_trace(go.Scatter(x=df.index, y=df['LB'], mode='lines', name='LB'))\n",
        "\n",
        "# # Update layout with titles and labels\n",
        "# fig.update_layout(title='BOlinger band',\n",
        "#                   xaxis_title='Time',\n",
        "#                   yaxis_title='Value',\n",
        "#                   xaxis=dict(rangeslider=dict(visible=True)))  # Add range slider\n",
        "\n",
        "# # Show the plot\n",
        "# fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zLmeuffEYSJB"
      },
      "outputs": [],
      "source": [
        "df = df.drop(columns = ['MB', 'UB', 'LB'])\n",
        "# df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2NS_GkBXYSJB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "def RSI(Df, n = 7):\n",
        "    df = Df.copy()\n",
        "    df['change'] = df['Adj Close'] - df['Adj Close'].shift(1)\n",
        "    df[\"gain\"] = np.where(df['change'] >=0, df['change'], 0)\n",
        "    df[\"loss\"] = np.where(df['change'] <=0, -1*df['change'], 0)\n",
        "    df['avg_gain'] = df['gain'].ewm(alpha = 1/n, min_periods = n).mean()\n",
        "    df['avg_loss'] = df['loss'].ewm(alpha = 1/n, min_periods = n).mean()\n",
        "    df['rs'] = df['avg_gain']/df['avg_loss']\n",
        "    df['RSI'] = 100 - (100/(1 + df['rs']))\n",
        "    return df['RSI']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8LGcvpJYSJB"
      },
      "outputs": [],
      "source": [
        "df['RSI'] = RSI(df)\n",
        "# df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z5UtM3BVYSJC"
      },
      "outputs": [],
      "source": [
        "def ADX(Df, n=7):\n",
        "    df = Df.copy()\n",
        "    df['upmove'] = df['High'] - df['High'].shift()\n",
        "    df['downmove'] = df['Low'].shift() - df['Low']\n",
        "    df['+dm'] = np.where((df['upmove'] > df['downmove']) & (df['upmove'] > 0), df['upmove'], 0)\n",
        "    df['-dm'] = np.where((df['downmove'] > df['upmove']) & (df['downmove'] > 0), df['downmove'], 0)\n",
        "    df['+di'] = 100 * (df['+dm'] / df['ATR']).ewm(com=n, min_periods=n).mean()\n",
        "    df['-di'] = 100 * (df['-dm'] / df['ATR']).ewm(com=n, min_periods=n).mean()\n",
        "    df['DX'] = (abs(df['+di'] - df['-di']) / (df['+di'] + df['-di'])) * 100\n",
        "    df['ADX'] = df['DX'].ewm(span=n, min_periods=n).mean()\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ulq6KmTwYSJC"
      },
      "outputs": [],
      "source": [
        "df = ADX(df)\n",
        "# df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nfFKU8JEYSJC"
      },
      "outputs": [],
      "source": [
        "\n",
        "df.drop(columns= ['upmove','downmove', '+dm', '-dm', '+di', '-di', 'DX'],inplace= True)\n",
        "# df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PzwknCbhYSJC"
      },
      "outputs": [],
      "source": [
        "bitcoin_price = pd.DataFrame(df[['Adj Close', 'macd_signal', 'ATR', 'BB_width', 'RSI', 'ADX']])\n",
        "# bitcoin_price.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UAeHG_asYSJC"
      },
      "outputs": [],
      "source": [
        "bitcoin_price.dropna(inplace= True)\n",
        "# bitcoin_price"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AQLe_7gUYSJC"
      },
      "outputs": [],
      "source": [
        "# bitcoin_price['Adj Close'][1:6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "paT63DkaYSJC"
      },
      "outputs": [],
      "source": [
        "# len(bitcoin_price['Adj Close']-window_size+horizon)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-zS-9Bq8YSJD"
      },
      "outputs": [],
      "source": [
        "labels_list = []\n",
        "feature_list = []\n",
        "window_size = 15\n",
        "horizon = 7\n",
        "feature_array = np.array(bitcoin_price)\n",
        "for i in range(0, len(bitcoin_price['Adj Close'])-(window_size+horizon-1)):\n",
        "    feature_list.append(np.array(feature_array[i:i+window_size]))\n",
        "    labels_list.append(np.array(bitcoin_price['Adj Close'][i+window_size:i+window_size+horizon]))\n",
        "\n",
        "# Convert the list of arrays to a numpy array\n",
        "labels = np.array(labels_list)\n",
        "feature = np.array(feature_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6k5XEndAYSJD"
      },
      "outputs": [],
      "source": [
        "# feature.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wXiBHgIAYSJD"
      },
      "outputs": [],
      "source": [
        "# labels.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8xPhjyxYSJD"
      },
      "outputs": [],
      "source": [
        "# scaler = MinMaxScaler()\n",
        "# data_scaled = scaler.fit_transform(bitcoin_price)\n",
        "#\n",
        "data_scaled = bitcoin_price"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXhzzcNPYSJD"
      },
      "outputs": [],
      "source": [
        "# data_scaled.head(15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTuInbBiYSJD"
      },
      "outputs": [],
      "source": [
        "def get_labelled_window(x, horizon=1):\n",
        "    return x[:, :-horizon], x[:, -horizon:]\n",
        "\n",
        "\n",
        "\n",
        "def make_windows(x,window_size,horizon):\n",
        "    #Create a window of specific window size (add the horizon to the end of the window for fuether labelling)\n",
        "    window_step = np.expand_dims(np.arange(window_size+horizon), axis =0)\n",
        "    # print(window_step)\n",
        "    # create a 2D array of multiple window steps(minus 1 to account for 0 indexing)\n",
        "    window_indexes = window_step + np.expand_dims(np.arange(len(x)- (window_size+horizon -1)),axis = 0).T\n",
        "    # print(window_indexes)\n",
        "\n",
        "    windowed_array = x[window_indexes]\n",
        "\n",
        "    windows, labelsx = get_labelled_window(windowed_array,horizon=horizon )\n",
        "\n",
        "    return windows, labelsx\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3bbY3QKYSJD"
      },
      "outputs": [],
      "source": [
        "# window_size = 15\n",
        "# horizon = 7\n",
        "# data_scaled = data_scaled.reset_index(drop=True)\n",
        "# full_windows, full_labels = make_windows(data_scaled, window_size=window_size, horizon=horizon)\n",
        "# full_windows.shape,full_labels.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8O-v9dxCYSJD"
      },
      "outputs": [],
      "source": [
        "def make_train_test_splits(windows, labels, test_split = 0.2):\n",
        "    split_size = int(len(windows)* (1-test_split))\n",
        "    train_windows = windows[:split_size]\n",
        "    train_labels = labels[:split_size]\n",
        "    test_windows = windows[split_size:]\n",
        "    test_labels = labels[split_size:]\n",
        "    return train_windows, test_windows, train_labels, test_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvs7TzMuYSJE",
        "outputId": "0e0183f5-9107-4bc3-9070-511f9028a11a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((2752, 15, 6), (688, 15, 6), (2752, 7), (688, 7))"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_windows, test_windows, train_labels, test_labels = make_train_test_splits(feature,labels)\n",
        "train_windows.shape, (test_windows).shape, (train_labels).shape, (test_labels).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55GhnP80YSJE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiaiNs2ZYSJE"
      },
      "source": [
        "model 8 (with out using minmax_scaler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJX2geA6YSJE"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "callback = EarlyStopping(\n",
        "    monitor=\"val_loss\",#quantity to monitor\n",
        "    min_delta=0.0001,#Minimum change in the monnitored quantity as an improvement\n",
        "    patience=20,#No of epochs with no improvement\n",
        "    verbose=1,\n",
        "    mode=\"auto\",\n",
        "    baseline=None,\n",
        "    restore_best_weights=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTywlVseYSJF",
        "outputId": "e1873046-f5db-4c72-ac23-30ed372ca7b4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "3405/3405 [==============================] - 134s 38ms/step - loss: 3357.2751 - mae: 3357.2751 - val_loss: 11363.8848 - val_mae: 11363.8848\n",
            "Epoch 2/100\n",
            "3405/3405 [==============================] - 125s 37ms/step - loss: 2074.4639 - mae: 2074.4639 - val_loss: 6172.1191 - val_mae: 6172.1191\n",
            "Epoch 3/100\n",
            "3405/3405 [==============================] - 124s 36ms/step - loss: 2136.8721 - mae: 2136.8721 - val_loss: 13301.5645 - val_mae: 13301.5645\n",
            "Epoch 4/100\n",
            "3405/3405 [==============================] - 126s 37ms/step - loss: 1795.5826 - mae: 1795.5826 - val_loss: 6465.0161 - val_mae: 6465.0161\n",
            "Epoch 5/100\n",
            "3405/3405 [==============================] - 123s 36ms/step - loss: 1522.2441 - mae: 1522.2441 - val_loss: 5414.4580 - val_mae: 5414.4580\n",
            "Epoch 6/100\n",
            "3405/3405 [==============================] - 124s 36ms/step - loss: 1401.8179 - mae: 1401.8179 - val_loss: 7069.0259 - val_mae: 7069.0259\n",
            "Epoch 7/100\n",
            "3405/3405 [==============================] - 123s 36ms/step - loss: 1297.6102 - mae: 1297.6102 - val_loss: 4853.8750 - val_mae: 4853.8750\n",
            "Epoch 8/100\n",
            "3405/3405 [==============================] - 123s 36ms/step - loss: 2083.5173 - mae: 2083.5173 - val_loss: 13339.5430 - val_mae: 13339.5430\n",
            "Epoch 9/100\n",
            "3405/3405 [==============================] - 126s 37ms/step - loss: 1914.4459 - mae: 1914.4459 - val_loss: 7477.2275 - val_mae: 7477.2275\n",
            "Epoch 10/100\n",
            "3405/3405 [==============================] - 124s 36ms/step - loss: 1831.7445 - mae: 1831.7445 - val_loss: 7070.5874 - val_mae: 7070.5874\n",
            "Epoch 11/100\n",
            "3405/3405 [==============================] - 124s 36ms/step - loss: 1805.8124 - mae: 1805.8124 - val_loss: 7718.3867 - val_mae: 7718.3867\n",
            "Epoch 12/100\n",
            "3405/3405 [==============================] - 124s 36ms/step - loss: 1631.7222 - mae: 1631.7222 - val_loss: 6056.0835 - val_mae: 6056.0835\n",
            "Epoch 13/100\n",
            "3405/3405 [==============================] - 124s 36ms/step - loss: 1428.4695 - mae: 1428.4695 - val_loss: 5286.5322 - val_mae: 5286.5322\n",
            "Epoch 14/100\n",
            "3405/3405 [==============================] - 124s 37ms/step - loss: 1296.6904 - mae: 1296.6904 - val_loss: 5807.4565 - val_mae: 5807.4565\n",
            "Epoch 15/100\n",
            "3405/3405 [==============================] - 124s 37ms/step - loss: 1945.0745 - mae: 1945.0745 - val_loss: 5658.8154 - val_mae: 5658.8154\n",
            "Epoch 16/100\n",
            "3405/3405 [==============================] - 123s 36ms/step - loss: 2032.6831 - mae: 2032.6831 - val_loss: 8830.1465 - val_mae: 8830.1465\n",
            "Epoch 17/100\n",
            "3405/3405 [==============================] - 125s 37ms/step - loss: 1680.5045 - mae: 1680.5045 - val_loss: 5567.7715 - val_mae: 5567.7715\n",
            "Epoch 18/100\n",
            "3405/3405 [==============================] - 126s 37ms/step - loss: 1534.6438 - mae: 1534.6438 - val_loss: 12055.2285 - val_mae: 12055.2285\n",
            "Epoch 19/100\n",
            "3405/3405 [==============================] - 125s 37ms/step - loss: 2124.3687 - mae: 2124.3687 - val_loss: 12544.5391 - val_mae: 12544.5391\n",
            "Epoch 20/100\n",
            "3405/3405 [==============================] - 124s 36ms/step - loss: 1636.7322 - mae: 1636.7322 - val_loss: 6310.5083 - val_mae: 6310.5083\n",
            "Epoch 21/100\n",
            "3405/3405 [==============================] - 123s 36ms/step - loss: 1281.3047 - mae: 1281.3047 - val_loss: 5168.9111 - val_mae: 5168.9111\n",
            "Epoch 22/100\n",
            "3405/3405 [==============================] - 124s 37ms/step - loss: 1126.2098 - mae: 1126.2098 - val_loss: 4672.1709 - val_mae: 4672.1709\n",
            "Epoch 23/100\n",
            "3405/3405 [==============================] - 121s 36ms/step - loss: 984.8393 - mae: 984.8393 - val_loss: 3718.8789 - val_mae: 3718.8789\n",
            "Epoch 24/100\n",
            "3405/3405 [==============================] - 122s 36ms/step - loss: 939.3259 - mae: 939.3259 - val_loss: 3639.6836 - val_mae: 3639.6836\n",
            "Epoch 25/100\n",
            "3405/3405 [==============================] - 120s 35ms/step - loss: 911.2365 - mae: 911.2365 - val_loss: 3742.5989 - val_mae: 3742.5989\n",
            "Epoch 26/100\n",
            "3405/3405 [==============================] - 121s 36ms/step - loss: 879.7531 - mae: 879.7531 - val_loss: 3641.9460 - val_mae: 3641.9460\n",
            "Epoch 27/100\n",
            "3405/3405 [==============================] - 122s 36ms/step - loss: 870.1327 - mae: 870.1327 - val_loss: 4110.5210 - val_mae: 4110.5210\n",
            "Epoch 28/100\n",
            "3405/3405 [==============================] - 122s 36ms/step - loss: 858.8002 - mae: 858.8002 - val_loss: 3692.6255 - val_mae: 3692.6255\n",
            "Epoch 29/100\n",
            "3405/3405 [==============================] - 121s 36ms/step - loss: 886.8402 - mae: 886.8402 - val_loss: 3558.8694 - val_mae: 3558.8694\n",
            "Epoch 30/100\n",
            " 217/3405 [>.............................] - ETA: 1:49 - loss: 929.2131 - mae: 929.2131"
          ]
        }
      ],
      "source": [
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense\n",
        "\n",
        "# Define input layer\n",
        "inputs = Input(shape=(window_size, 6))\n",
        "\n",
        "# Define LSTM layers\n",
        "lstm1 = LSTM(256, activation='relu', return_sequences=True)(inputs)\n",
        "lstm2 = LSTM(128, activation='relu', return_sequences=True)(lstm1)\n",
        "lstm3 = LSTM(128, activation='relu')(lstm2)\n",
        "\n",
        "# Output layer with a single unit\n",
        "outputs = Dense(horizon, activation='linear')(lstm3)\n",
        "\n",
        "# Create model\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='mae', optimizer='adam', metrics=['mae'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_windows,train_labels,\n",
        "          epochs=100, verbose=1,\n",
        "          batch_size=1, validation_data=(test_windows,test_labels),callbacks=callback)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fZxiM-HWYSJF"
      },
      "outputs": [],
      "source": [
        "def mean_absolute_scaled_error(y_true, y_pred, seasonality=1):\n",
        "    mae = np.mean(np.abs(y_true - y_pred))\n",
        "    naive_forecast = y_true[:-seasonality]\n",
        "    naive_mae = np.mean(np.abs(naive_forecast - y_true[seasonality:]))\n",
        "    mase = mae / naive_mae\n",
        "    return mase\n",
        "\n",
        "def evaluate_preds(y_true, y_pred):\n",
        "  # Make sure float32 (for metric calculations)\n",
        "  y_true = tf.cast(y_true, dtype=tf.float32)\n",
        "  y_pred = tf.cast(y_pred, dtype=tf.float32)\n",
        "\n",
        "  # Calculate various metrics\n",
        "  mae = tf.keras.metrics.mean_absolute_error(y_true, y_pred)\n",
        "  mse = tf.keras.metrics.mean_squared_error(y_true, y_pred)\n",
        "  rmse = tf.sqrt(mse)\n",
        "  huber_loss = tf.keras.losses.Huber()(y_true, y_pred)\n",
        "  mase = mean_absolute_scaled_error(y_true.numpy(), y_pred.numpy(),seasonality=1)\n",
        "\n",
        "  # Account for different sized metrics (for longer horizons, reduce to single number)\n",
        "  if mae.ndim > 0: # if mae isn't already a scalar, reduce it to one by aggregating tensors to mean\n",
        "    mae = tf.reduce_mean(mae)\n",
        "    mse = tf.reduce_mean(mse)\n",
        "    rmse = tf.reduce_mean(rmse)\n",
        "    huber_loss = tf.reduce_mean(huber_loss)\n",
        "    mase = tf.reduce_mean(mase)\n",
        "\n",
        "  print(\"For mae, mse, rmse and hubber : lower value is better.\\nmase :- A scaled eror is >1 if the forecast is worse than the naive and <1 if the forecast is better that the naive.\")\n",
        "  print(f\"\"\"\n",
        "    \"mae\": {mae.numpy()},\n",
        "    \"mse\": {mse.numpy()},\n",
        "    \"rmse\": {rmse.numpy()},\n",
        "    \"huber_loss\": {huber_loss.numpy()},\n",
        "    \"mase\": {mase}\n",
        "    \"\"\")\n",
        "  return {\n",
        "        \"mae\": mae.numpy(),\n",
        "        \"mse\": mse.numpy(),\n",
        "        \"rmse\": rmse.numpy(),\n",
        "        \"huber_loss\": huber_loss.numpy(),\n",
        "        \"mase\": mase.numpy()\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DR21FxvzYSJF"
      },
      "outputs": [],
      "source": [
        "forecast  = model.predict(test_windows)\n",
        "preds =(forecast)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bWWtFCMFYSJF"
      },
      "outputs": [],
      "source": [
        " test_labels.shape, preds.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "uIgh2MkeYSJL",
        "outputId": "0265349c-0109-4231-880b-27bae9584ddb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "For mae, mse, rmse and hubber : lower value is better.\n",
            "mase :- A scaled eror is >1 if the forecast is worse than the naive and <1 if the forecast is better that the naive.\n",
            "\n",
            "    \"mae\": 1225.068359375,\n",
            "    \"mse\": 3667159.75,\n",
            "    \"rmse\": 1409.69775390625,\n",
            "    \"huber_loss\": 1224.568359375,\n",
            "    \"mase\": 2.1983470916748047\n",
            "    \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'mae': 1225.0684,\n",
              " 'mse': 3667159.8,\n",
              " 'rmse': 1409.6978,\n",
              " 'huber_loss': 1224.5684,\n",
              " 'mase': 2.198347}"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate_preds(y_true= test_labels, y_pred= preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4qnxj744YSJL"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))  # Adjust size as needed\n",
        "plt.plot(pd.to_datetime(df_time['Date'][-len(preds):]), preds, label='Predicted')\n",
        "plt.plot(pd.to_datetime(df_time['Date'][-len(preds):]), tf.squeeze(test_labels), label='Actual',linestyle = \" \", marker='.')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Value')\n",
        "plt.title('Predicted vs Actual')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXslsACXYSJL"
      },
      "outputs": [],
      "source": [
        "x= df_time['Date'][-len(preds):])\n",
        "y = (list(preds))\n",
        "values = [item[0] for item in y]\n",
        "\n",
        "z = list(tf.squeeze(full_labels).numpy())\n",
        "df_onix = pd.DataFrame({'x':x, 'y':values, 'z':z})\n",
        "df_onix['x']=pd.to_datetime(df_onix['x'])\n",
        "\n",
        "df_onix.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KAc0NQTXYSJL"
      },
      "outputs": [],
      "source": [
        "# import plotly.graph_objects as go\n",
        "\n",
        "# # Assuming df_final is your DataFrame\n",
        "# # Create a Plotly figure\n",
        "# fig = go.Figure()\n",
        "\n",
        "# # Add traces for 'Appliances' and 'App_Pred'\n",
        "# fig.add_trace(go.Scatter(x=df_onix['x'], y=df_onix['y'], mode='lines', name='Appliances'))\n",
        "# fig.add_trace(go.Scatter(x=df_onix['x'], y=df_onix['z'], mode='lines', name='App_Pred'))\n",
        "\n",
        "# # Update layout with titles and labels\n",
        "# fig.update_layout(title='Appliances vs. App_Pred',\n",
        "#                   xaxis_title='Time',\n",
        "#                   yaxis_title='Value',\n",
        "#                   xaxis=dict(rangeslider=dict(visible=True)))  # Add range slider\n",
        "\n",
        "# # Show the plot\n",
        "# fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CpZGo2m7YSJM"
      },
      "outputs": [],
      "source": [
        "# test_windows.shape, (test_windows[0].reshape(1,test_windows[0].shape[0], test_windows[0].shape[1])).shape\n",
        "# test_windows.reshape(test_windows.shape[0], test_windows.shape[1], 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kyqKhHPAYSJM"
      },
      "outputs": [],
      "source": [
        "# test_windows[0],test_labels[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfA7m8sXYSJM"
      },
      "outputs": [],
      "source": [
        "# model.predict(test_windows[0].reshape(1,test_windows[0].shape[0], test_windows[0].shape[1])),test_labels[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8xUD-OoCYSJM"
      },
      "outputs": [],
      "source": [
        "model.save('model_10_multivariate_parameter_1.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KcqbNqOZYSJM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tEaikuEYSJM"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60o8uWEcYSJN"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 4708088,
          "sourceId": 7996305,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30674,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
