{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-23T07:34:34.554521Z","iopub.execute_input":"2024-04-23T07:34:34.554870Z","iopub.status.idle":"2024-04-23T07:34:34.559357Z","shell.execute_reply.started":"2024-04-23T07:34:34.554843Z","shell.execute_reply":"2024-04-23T07:34:34.558450Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"!pip install transformers[sentencepiece] datasets evaluate rouge_score sacrebleu ","metadata":{"execution":{"iopub.status.busy":"2024-04-23T07:34:35.542107Z","iopub.execute_input":"2024-04-23T07:34:35.542500Z","iopub.status.idle":"2024-04-23T07:34:52.782817Z","shell.execute_reply.started":"2024-04-23T07:34:35.542472Z","shell.execute_reply":"2024-04-23T07:34:52.781787Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.18.0)\nCollecting evaluate\n  Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\nCollecting rouge_score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting sacrebleu\n  Downloading sacrebleu-2.4.2-py3-none-any.whl.metadata (58 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.0/58.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: transformers[sentencepiece] in /opt/conda/lib/python3.10/site-packages (4.39.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]) (0.22.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]) (4.66.1)\nRequirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]) (0.2.0)\nRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]) (3.20.3)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (15.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.1.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets) (2024.2.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nCollecting responses<0.19 (from evaluate)\n  Downloading responses-0.18.0-py3-none-any.whl.metadata (29 kB)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge_score) (3.2.4)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\nCollecting portalocker (from sacrebleu)\n  Downloading portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.9.0)\nRequirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.4.6)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (5.2.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[sentencepiece]) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers[sentencepiece]) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[sentencepiece]) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[sentencepiece]) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[sentencepiece]) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[sentencepiece]) (2024.2.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\nDownloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sacrebleu-2.4.2-py3-none-any.whl (106 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading responses-0.18.0-py3-none-any.whl (38 kB)\nDownloading portalocker-2.8.2-py3-none-any.whl (17 kB)\nBuilding wheels for collected packages: rouge_score\n  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=1b47440ef5f2ff91380dd42d8bb73bdcd1feb4f02c983d08ba0381ac45955931\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\nSuccessfully built rouge_score\nInstalling collected packages: portalocker, sacrebleu, rouge_score, responses, evaluate\nSuccessfully installed evaluate-0.4.1 portalocker-2.8.2 responses-0.18.0 rouge_score-0.1.2 sacrebleu-2.4.2\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install --upgrade accelerate\n!pip uninstall -y transformers accelerate\n!pip install transformers accelerate","metadata":{"execution":{"iopub.status.busy":"2024-04-23T07:34:52.784836Z","iopub.execute_input":"2024-04-23T07:34:52.785192Z","iopub.status.idle":"2024-04-23T07:35:31.699265Z","shell.execute_reply.started":"2024-04-23T07:34:52.785161Z","shell.execute_reply":"2024-04-23T07:35:31.698089Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.29.3)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.2)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.22.2)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2024.2.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nFound existing installation: transformers 4.39.3\nUninstalling transformers-4.39.3:\n  Successfully uninstalled transformers-4.39.3\nFound existing installation: accelerate 0.29.3\nUninstalling accelerate-0.29.3:\n  Successfully uninstalled accelerate-0.29.3\nCollecting transformers\n  Downloading transformers-4.40.0-py3-none-any.whl.metadata (137 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.6/137.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting accelerate\n  Downloading accelerate-0.29.3-py3-none-any.whl.metadata (18 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.22.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nCollecting tokenizers<0.20,>=0.19 (from transformers)\n  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.2)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nDownloading transformers-4.40.0-py3-none-any.whl (9.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading accelerate-0.29.3-py3-none-any.whl (297 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.6/297.6 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: tokenizers, accelerate, transformers\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.15.2\n    Uninstalling tokenizers-0.15.2:\n      Successfully uninstalled tokenizers-0.15.2\nSuccessfully installed accelerate-0.29.3 tokenizers-0.19.1 transformers-4.40.0\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import pipeline, set_seed\nfrom datasets import load_dataset, load_from_disk\nimport matplotlib.pyplot as plt\n\nimport pandas as pd\nfrom datasets import load_dataset, load_metric\nfrom transformers import BertTokenizerFast, DataCollatorForTokenClassification\nfrom transformers import AutoModelForSeq2SeqLM, AutoTokenizer, AutoModelForTokenClassification\nimport nltk\nfrom nltk.tokenize import sent_tokenize\n\nfrom tqdm import tqdm\nimport torch\n\nnltk.download(\"punkt\")","metadata":{"execution":{"iopub.status.busy":"2024-04-23T07:35:31.700912Z","iopub.execute_input":"2024-04-23T07:35:31.701781Z","iopub.status.idle":"2024-04-23T07:35:50.837676Z","shell.execute_reply.started":"2024-04-23T07:35:31.701741Z","shell.execute_reply":"2024-04-23T07:35:50.836673Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"2024-04-23 07:35:38.730248: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-23 07:35:38.730394: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-23 07:35:38.880759: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"markdown","source":"https://huggingface.co/datasets/conll2003","metadata":{}},{"cell_type":"code","source":"dataset = load_dataset(\"conll2003\")","metadata":{"execution":{"iopub.status.busy":"2024-04-23T07:35:50.840065Z","iopub.execute_input":"2024-04-23T07:35:50.840805Z","iopub.status.idle":"2024-04-23T07:35:55.656069Z","shell.execute_reply.started":"2024-04-23T07:35:50.840769Z","shell.execute_reply":"2024-04-23T07:35:55.655214Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"Downloading data: 100%|██████████| 1.23M/1.23M [00:00<00:00, 6.33MB/s]\nDownloading data: 100%|██████████| 312k/312k [00:00<00:00, 3.15MB/s]\nDownloading data: 100%|██████████| 283k/283k [00:00<00:00, 2.96MB/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/14041 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac851e328c964709a2ed393a6ef1b194"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/3250 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2bb8ce6d80fa404f825ca1c8c88d629b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/3453 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2fef3b2960914486bd9b7ef0e2650388"}},"metadata":{}}]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2024-04-23T07:36:00.461536Z","iopub.execute_input":"2024-04-23T07:36:00.461888Z","iopub.status.idle":"2024-04-23T07:36:00.468309Z","shell.execute_reply.started":"2024-04-23T07:36:00.461859Z","shell.execute_reply":"2024-04-23T07:36:00.467268Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n        num_rows: 14041\n    })\n    validation: Dataset({\n        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n        num_rows: 3250\n    })\n    test: Dataset({\n        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n        num_rows: 3453\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"dataset['train'].features['tokens']","metadata":{"execution":{"iopub.status.busy":"2024-04-23T07:36:01.756213Z","iopub.execute_input":"2024-04-23T07:36:01.756606Z","iopub.status.idle":"2024-04-23T07:36:01.763784Z","shell.execute_reply.started":"2024-04-23T07:36:01.756575Z","shell.execute_reply":"2024-04-23T07:36:01.762793Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)"},"metadata":{}}]},{"cell_type":"code","source":"dataset['train'].description","metadata":{"execution":{"iopub.status.busy":"2024-04-23T07:36:02.664116Z","iopub.execute_input":"2024-04-23T07:36:02.664978Z","iopub.status.idle":"2024-04-23T07:36:02.670566Z","shell.execute_reply.started":"2024-04-23T07:36:02.664946Z","shell.execute_reply":"2024-04-23T07:36:02.669706Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"'The shared task of CoNLL-2003 concerns language-independent named entity recognition. We will concentrate on\\nfour types of named entities: persons, locations, organizations and names of miscellaneous entities that do\\nnot belong to the previous three groups.\\n\\nThe CoNLL-2003 shared task data files contain four columns separated by a single space. Each word has been put on\\na separate line and there is an empty line after each sentence. The first item on each line is a word, the second\\na part-of-speech (POS) tag, the third a syntactic chunk tag and the fourth the named entity tag. The chunk tags\\nand the named entity tags have the format I-TYPE which means that the word is inside a phrase of type TYPE. Only\\nif two phrases of the same type immediately follow each other, the first word of the second phrase will have tag\\nB-TYPE to show that it starts a new phrase. A word with tag O is not part of a phrase. Note the dataset uses IOB2\\ntagging scheme, whereas the original dataset uses IOB1.\\n\\nFor more details see https://www.clips.uantwerpen.be/conll2003/ner/ and https://www.aclweb.org/anthology/W03-0419\\n'"},"metadata":{}}]},{"cell_type":"code","source":"dataset['train'].features['ner_tags']","metadata":{"execution":{"iopub.status.busy":"2024-04-23T07:36:03.493840Z","iopub.execute_input":"2024-04-23T07:36:03.494658Z","iopub.status.idle":"2024-04-23T07:36:03.500775Z","shell.execute_reply.started":"2024-04-23T07:36:03.494628Z","shell.execute_reply":"2024-04-23T07:36:03.499866Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'], id=None), length=-1, id=None)"},"metadata":{}}]},{"cell_type":"code","source":"dataset['train'].features['chunk_tags']","metadata":{"execution":{"iopub.status.busy":"2024-04-23T07:36:04.387449Z","iopub.execute_input":"2024-04-23T07:36:04.387809Z","iopub.status.idle":"2024-04-23T07:36:04.394390Z","shell.execute_reply.started":"2024-04-23T07:36:04.387783Z","shell.execute_reply":"2024-04-23T07:36:04.393501Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"Sequence(feature=ClassLabel(names=['O', 'B-ADJP', 'I-ADJP', 'B-ADVP', 'I-ADVP', 'B-CONJP', 'I-CONJP', 'B-INTJ', 'I-INTJ', 'B-LST', 'I-LST', 'B-NP', 'I-NP', 'B-PP', 'I-PP', 'B-PRT', 'I-PRT', 'B-SBAR', 'I-SBAR', 'B-UCP', 'I-UCP', 'B-VP', 'I-VP'], id=None), length=-1, id=None)"},"metadata":{}}]},{"cell_type":"code","source":"dataset['train'].features['pos_tags']","metadata":{"execution":{"iopub.status.busy":"2024-04-23T07:36:05.244449Z","iopub.execute_input":"2024-04-23T07:36:05.245058Z","iopub.status.idle":"2024-04-23T07:36:05.252090Z","shell.execute_reply.started":"2024-04-23T07:36:05.245006Z","shell.execute_reply":"2024-04-23T07:36:05.251090Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"Sequence(feature=ClassLabel(names=['\"', \"''\", '#', '$', '(', ')', ',', '.', ':', '``', 'CC', 'CD', 'DT', 'EX', 'FW', 'IN', 'JJ', 'JJR', 'JJS', 'LS', 'MD', 'NN', 'NNP', 'NNPS', 'NNS', 'NN|SYM', 'PDT', 'POS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'SYM', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WP$', 'WRB'], id=None), length=-1, id=None)"},"metadata":{}}]},{"cell_type":"code","source":"train_data = pd.DataFrame(dataset['train'])\nvalidation_data = pd.DataFrame(dataset['validation'])\ntest_data = pd.DataFrame(dataset['test'])","metadata":{"execution":{"iopub.status.busy":"2024-04-23T07:36:06.147790Z","iopub.execute_input":"2024-04-23T07:36:06.148168Z","iopub.status.idle":"2024-04-23T07:36:09.264131Z","shell.execute_reply.started":"2024-04-23T07:36:06.148138Z","shell.execute_reply":"2024-04-23T07:36:09.263356Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train_data.info()","metadata":{"execution":{"iopub.status.busy":"2024-04-23T07:36:11.300467Z","iopub.execute_input":"2024-04-23T07:36:11.300820Z","iopub.status.idle":"2024-04-23T07:36:11.341231Z","shell.execute_reply.started":"2024-04-23T07:36:11.300794Z","shell.execute_reply":"2024-04-23T07:36:11.340195Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 14041 entries, 0 to 14040\nData columns (total 5 columns):\n #   Column      Non-Null Count  Dtype \n---  ------      --------------  ----- \n 0   id          14041 non-null  object\n 1   tokens      14041 non-null  object\n 2   pos_tags    14041 non-null  object\n 3   chunk_tags  14041 non-null  object\n 4   ner_tags    14041 non-null  object\ndtypes: object(5)\nmemory usage: 548.6+ KB\n","output_type":"stream"}]},{"cell_type":"code","source":"train_data['tokens']","metadata":{"execution":{"iopub.status.busy":"2024-04-23T07:36:12.362921Z","iopub.execute_input":"2024-04-23T07:36:12.363750Z","iopub.status.idle":"2024-04-23T07:36:12.373719Z","shell.execute_reply.started":"2024-04-23T07:36:12.363718Z","shell.execute_reply":"2024-04-23T07:36:12.372828Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"0        [EU, rejects, German, call, to, boycott, Briti...\n1                                       [Peter, Blackburn]\n2                                   [BRUSSELS, 1996-08-22]\n3        [The, European, Commission, said, on, Thursday...\n4        [Germany, 's, representative, to, the, Europea...\n                               ...                        \n14036                                      [on, Friday, :]\n14037                                      [Division, two]\n14038                            [Plymouth, 2, Preston, 1]\n14039                                    [Division, three]\n14040                             [Swansea, 1, Lincoln, 2]\nName: tokens, Length: 14041, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"train_data['tokens'][0]","metadata":{"execution":{"iopub.status.busy":"2024-04-23T07:36:13.301471Z","iopub.execute_input":"2024-04-23T07:36:13.302408Z","iopub.status.idle":"2024-04-23T07:36:13.308324Z","shell.execute_reply.started":"2024-04-23T07:36:13.302362Z","shell.execute_reply":"2024-04-23T07:36:13.307354Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']"},"metadata":{}}]},{"cell_type":"code","source":"train_data[['tokens','ner_tags']].iloc[0]","metadata":{"execution":{"iopub.status.busy":"2024-04-23T07:36:14.062187Z","iopub.execute_input":"2024-04-23T07:36:14.062554Z","iopub.status.idle":"2024-04-23T07:36:14.073500Z","shell.execute_reply.started":"2024-04-23T07:36:14.062527Z","shell.execute_reply":"2024-04-23T07:36:14.072461Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"tokens      [EU, rejects, German, call, to, boycott, Briti...\nner_tags                          [3, 0, 7, 0, 0, 0, 7, 0, 0]\nName: 0, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\ntokenizer","metadata":{"execution":{"iopub.status.busy":"2024-04-23T07:36:15.012073Z","iopub.execute_input":"2024-04-23T07:36:15.013059Z","iopub.status.idle":"2024-04-23T07:36:16.376449Z","shell.execute_reply.started":"2024-04-23T07:36:15.013004Z","shell.execute_reply":"2024-04-23T07:36:16.375477Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92edc585ee64415ea4d46ab5800e825a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33e320be7e0d4292a9a7f217d33676c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45f1db2cf757487fb159b0ef88aeeb9e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"257c6f13dd364fb782615098130280ed"}},"metadata":{}},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"BertTokenizerFast(name_or_path='bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n}"},"metadata":{}}]},{"cell_type":"code","source":"example_text = dataset['train'][0]\nexample_text['tokens']","metadata":{"execution":{"iopub.status.busy":"2024-04-23T07:36:17.808962Z","iopub.execute_input":"2024-04-23T07:36:17.809928Z","iopub.status.idle":"2024-04-23T07:36:17.816846Z","shell.execute_reply.started":"2024-04-23T07:36:17.809897Z","shell.execute_reply":"2024-04-23T07:36:17.815898Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']"},"metadata":{}}]},{"cell_type":"code","source":"example_tokenization = tokenizer(example_text['tokens'], is_split_into_words = True)\nexample_tokenization","metadata":{"execution":{"iopub.status.busy":"2024-04-23T07:36:18.495334Z","iopub.execute_input":"2024-04-23T07:36:18.495681Z","iopub.status.idle":"2024-04-23T07:36:18.502730Z","shell.execute_reply.started":"2024-04-23T07:36:18.495656Z","shell.execute_reply":"2024-04-23T07:36:18.501746Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [101, 7327, 19164, 2446, 2655, 2000, 17757, 2329, 12559, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"},"metadata":{}}]},{"cell_type":"code","source":"word_ids = example_tokenization.word_ids(batch_index = 0)\nword_ids ","metadata":{"execution":{"iopub.status.busy":"2024-04-23T07:36:19.185909Z","iopub.execute_input":"2024-04-23T07:36:19.186289Z","iopub.status.idle":"2024-04-23T07:36:19.193963Z","shell.execute_reply.started":"2024-04-23T07:36:19.186260Z","shell.execute_reply":"2024-04-23T07:36:19.193074Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"[None, 0, 1, 2, 3, 4, 5, 6, 7, 8, None]"},"metadata":{}}]},{"cell_type":"code","source":"tokens = tokenizer.convert_ids_to_tokens(example_tokenization['input_ids'])\ntokens","metadata":{"execution":{"iopub.status.busy":"2024-04-23T07:36:19.875613Z","iopub.execute_input":"2024-04-23T07:36:19.876491Z","iopub.status.idle":"2024-04-23T07:36:19.882734Z","shell.execute_reply.started":"2024-04-23T07:36:19.876459Z","shell.execute_reply":"2024-04-23T07:36:19.881709Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"['[CLS]',\n 'eu',\n 'rejects',\n 'german',\n 'call',\n 'to',\n 'boycott',\n 'british',\n 'lamb',\n '.',\n '[SEP]']"},"metadata":{}}]},{"cell_type":"code","source":"example_tokenization['input_ids']","metadata":{"execution":{"iopub.status.busy":"2024-04-23T07:36:20.762860Z","iopub.execute_input":"2024-04-23T07:36:20.763601Z","iopub.status.idle":"2024-04-23T07:36:20.769425Z","shell.execute_reply.started":"2024-04-23T07:36:20.763559Z","shell.execute_reply":"2024-04-23T07:36:20.768500Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"[101, 7327, 19164, 2446, 2655, 2000, 17757, 2329, 12559, 1012, 102]"},"metadata":{}}]},{"cell_type":"markdown","source":"1. **Function Definition**: \n    ```python\n    def tokenize_and_aligin_labels(examples, label_all_tokens=True):\n    ```\n    This function is defined with the name `tokenize_and_aligin_labels` which takes two parameters `examples` and `label_all_tokens`. The `label_all_tokens` parameter is set to `True` by default.\n\n2. **Tokenization**:\n    ```python\n    tokenized_input = tokenizer(examples['tokens'], truncation=True, is_split_into_words=True)\n    ```\n    Here, it appears that `tokenizer` is a function or object that tokenizes input. It's applied to the `examples['tokens']` data, presumably a list of tokens, with truncation enabled and assuming that the input is already split into words.\n\n3. **Initialization**:\n    ```python\n    labels = []\n    ```\n    An empty list `labels` is initialized. This list will store the labels for each token in the tokenized input.\n\n4. **Iterating over Examples**:\n    ```python\n    for i, label in enumerate(examples['ner_tags']):\n    ```\n    This loop iterates over the examples in `examples['ner_tags']`. `enumerate()` is used to get both the index `i` and the label `label` for each example.\n\n5. **Word IDs Extraction**:\n    ```python\n    word_ids = tokenized_input.word_ids(batch_index=i)\n    ```\n    For each example, it extracts the word IDs from the `tokenized_input` using the `word_ids()` method. These IDs represent the position of each word in the tokenized input.\n\n6. **Initializing Previous Word Index**:\n    ```python\n    previous_word_idx = None\n    ```\n    Initialize the `previous_word_idx` variable to `None`. This variable will be used to track the index of the previous word in the tokenized input.\n\n7. **Iterating over Word IDs**:\n    ```python\n    for word_idx in word_ids:\n    ```\n    This loop iterates over each word ID in `word_ids`.\n\n8. **Label Assignment**:\n    ```python\n    if word_idx is None:\n        label_ids.append(-100)\n    ```\n    If the `word_idx` is `None`, it means that the word is not aligned with any token. In such cases, `-100` is appended to `label_ids`.\n\n9. **Handling Repeated Tokens**:\n    ```python\n    elif word_idx != previous_word_idx:\n        label_ids.append(label[word_idx])\n    else:\n        label_ids.append(label[word_idx] if label_all_tokens else -100)\n    ```\n    If the `word_idx` is different from the `previous_word_idx`, it means that the word corresponds to a new token. In this case, the label for that token is appended to `label_ids`. If `label_all_tokens` is `True`, then the label is appended; otherwise, `-100` is appended.\n\n10. **Updating Previous Word Index**:\n    ```python\n    previous_word_idx = word_idx\n    ```\n    Update `previous_word_idx` to the current `word_idx` for the next iteration.\n\n11. **Appending Labels**:\n    ```python\n    labels.append(label_ids)\n    ```\n    After processing all word IDs for an example, the list of label IDs for that example is appended to the `labels` list.\n\n12. **Adding Labels to Tokenized Input**:\n    ```python\n    tokenized_input['labels'] = labels\n    ```\n    Finally, the `labels` list is added to the `tokenized_input` dictionary under the key `'labels'`.\n\n13. **Return**:\n    ```python\n    return tokenized_input\n    ```\n    The function returns the modified `tokenized_input` dictionary with labels added.","metadata":{}},{"cell_type":"code","source":"def tokenize_and_aligin_labels(examples, label_all_tokens = True):\n    # tokenize ids\n    tokenized_input = tokenizer(examples['tokens'], truncation = True, is_split_into_words = True)\n    labels = []\n    \n    for i, label in enumerate(examples['ner_tags']):\n        word_ids = tokenized_input.word_ids(batch_index = i)\n        \n        previous_word_idx = None\n        label_ids = []\n        \n        for word_idx in word_ids:\n            if word_idx is None:\n                label_ids.append(-100)\n            \n            elif word_idx != previous_word_idx:\n                label_ids.append((label[word_idx]))\n                \n            else:\n                label_ids.append(label[word_idx] if label_all_tokens else -100)\n            \n            previous_word_idx = word_idx\n        labels.append(label_ids)\n    tokenized_input['labels'] = labels   \n    return tokenized_input","metadata":{"execution":{"iopub.status.busy":"2024-04-23T07:36:21.891549Z","iopub.execute_input":"2024-04-23T07:36:21.891923Z","iopub.status.idle":"2024-04-23T07:36:21.900919Z","shell.execute_reply.started":"2024-04-23T07:36:21.891895Z","shell.execute_reply":"2024-04-23T07:36:21.899804Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# def tokenize_and_align_labels(examples, label_all_tokens=True):\n#     # tokenize ids\n#     tokenized_input = tokenizer(examples['tokens'], truncation=True, is_split_into_words=True)\n#     labels = []\n    \n#     for i, ner_tag in enumerate(examples['ner_tags']):\n#         word_ids = tokenized_input.word_ids(batch_index=i)\n        \n#         previous_word_idx = None\n#         label_ids = []\n        \n#         for word_idx in word_ids:\n#             if word_idx is None:\n#                 label_ids.append(-100)\n#             elif word_idx != previous_word_idx:\n#                 label_ids.append(ner_tag)  # Use the NER tag directly\n#             else:\n#                 label_ids.append(ner_tag if label_all_tokens else -100)\n            \n#             previous_word_idx = word_idx\n        \n#         labels.append(label_ids)\n    \n#     tokenized_input['labels'] = labels   \n#     return tokenized_input\n","metadata":{"execution":{"iopub.status.busy":"2024-04-23T07:36:22.114930Z","iopub.execute_input":"2024-04-23T07:36:22.117472Z","iopub.status.idle":"2024-04-23T07:36:22.122078Z","shell.execute_reply.started":"2024-04-23T07:36:22.117439Z","shell.execute_reply":"2024-04-23T07:36:22.120964Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"A = tokenize_and_aligin_labels(dataset['train'][4:5])\nA","metadata":{"execution":{"iopub.status.busy":"2024-04-23T07:36:22.329377Z","iopub.execute_input":"2024-04-23T07:36:22.329996Z","iopub.status.idle":"2024-04-23T07:36:22.337680Z","shell.execute_reply.started":"2024-04-23T07:36:22.329965Z","shell.execute_reply":"2024-04-23T07:36:22.336694Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [[101, 2762, 1005, 1055, 4387, 2000, 1996, 2647, 2586, 1005, 1055, 15651, 2837, 14121, 1062, 9328, 5804, 2056, 2006, 9317, 10390, 2323, 4965, 8351, 4168, 4017, 2013, 3032, 2060, 2084, 3725, 2127, 1996, 4045, 6040, 2001, 24509, 1012, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[-100, 5, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, -100]]}"},"metadata":{}}]},{"cell_type":"code","source":"for token, label in zip(tokenizer.convert_ids_to_tokens(A['input_ids'][0]), A['labels'][0]):\n    print(f\"{token:_<40} {label}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-23T07:36:23.177293Z","iopub.execute_input":"2024-04-23T07:36:23.177652Z","iopub.status.idle":"2024-04-23T07:36:23.183496Z","shell.execute_reply.started":"2024-04-23T07:36:23.177623Z","shell.execute_reply":"2024-04-23T07:36:23.182490Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"[CLS]___________________________________ -100\ngermany_________________________________ 5\n'_______________________________________ 0\ns_______________________________________ 0\nrepresentative__________________________ 0\nto______________________________________ 0\nthe_____________________________________ 0\neuropean________________________________ 3\nunion___________________________________ 4\n'_______________________________________ 0\ns_______________________________________ 0\nveterinary______________________________ 0\ncommittee_______________________________ 0\nwerner__________________________________ 1\nz_______________________________________ 2\n##wing__________________________________ 2\n##mann__________________________________ 2\nsaid____________________________________ 0\non______________________________________ 0\nwednesday_______________________________ 0\nconsumers_______________________________ 0\nshould__________________________________ 0\nbuy_____________________________________ 0\nsheep___________________________________ 0\n##me____________________________________ 0\n##at____________________________________ 0\nfrom____________________________________ 0\ncountries_______________________________ 0\nother___________________________________ 0\nthan____________________________________ 0\nbritain_________________________________ 5\nuntil___________________________________ 0\nthe_____________________________________ 0\nscientific______________________________ 0\nadvice__________________________________ 0\nwas_____________________________________ 0\nclearer_________________________________ 0\n._______________________________________ 0\n[SEP]___________________________________ -100\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenized_dataset = dataset.map(tokenize_and_aligin_labels,batched = True)","metadata":{"execution":{"iopub.status.busy":"2024-04-23T07:36:23.961879Z","iopub.execute_input":"2024-04-23T07:36:23.962291Z","iopub.status.idle":"2024-04-23T07:36:26.964261Z","shell.execute_reply.started":"2024-04-23T07:36:23.962261Z","shell.execute_reply":"2024-04-23T07:36:26.963357Z"},"trusted":true},"execution_count":28,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/14041 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e51aa7c8b464499d9d39f62f444dd7b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3250 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2395bfa1de1b4378b8f22d7106cab8f5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3453 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e659ce8b8f074ebeb468d851b3b19936"}},"metadata":{}}]},{"cell_type":"code","source":"tokenized_dataset['train']","metadata":{"execution":{"iopub.status.busy":"2024-04-23T07:36:26.965879Z","iopub.execute_input":"2024-04-23T07:36:26.966190Z","iopub.status.idle":"2024-04-23T07:36:26.972615Z","shell.execute_reply.started":"2024-04-23T07:36:26.966165Z","shell.execute_reply":"2024-04-23T07:36:26.971652Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n    num_rows: 14041\n})"},"metadata":{}}]},{"cell_type":"code","source":"model = AutoModelForTokenClassification.from_pretrained('bert-base-uncased',num_labels = 9)","metadata":{"execution":{"iopub.status.busy":"2024-04-23T07:36:28.266990Z","iopub.execute_input":"2024-04-23T07:36:28.268149Z","iopub.status.idle":"2024-04-23T07:36:30.362345Z","shell.execute_reply.started":"2024-04-23T07:36:28.268108Z","shell.execute_reply":"2024-04-23T07:36:30.361430Z"},"trusted":true},"execution_count":30,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b499d8b93234708861aa8393246ac71"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer","metadata":{"execution":{"iopub.status.busy":"2024-04-23T07:36:32.530966Z","iopub.execute_input":"2024-04-23T07:36:32.531741Z","iopub.status.idle":"2024-04-23T07:36:32.550645Z","shell.execute_reply.started":"2024-04-23T07:36:32.531711Z","shell.execute_reply":"2024-04-23T07:36:32.549778Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"argumnet = TrainingArguments(\"test_ner\",\n                   evaluation_strategy = 'epoch',\n                  learning_rate = 2e-5,\n                  per_device_train_batch_size = 16,\n                  per_device_eval_batch_size = 16,\n                  num_train_epochs =5, # number of epochs for tainning\n                  weight_decay = 0.01)\nargumnet","metadata":{"execution":{"iopub.status.busy":"2024-04-23T07:37:23.039924Z","iopub.execute_input":"2024-04-23T07:37:23.040763Z","iopub.status.idle":"2024-04-23T07:37:23.072923Z","shell.execute_reply.started":"2024-04-23T07:37:23.040732Z","shell.execute_reply":"2024-04-23T07:37:23.072010Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"TrainingArguments(\n_n_gpu=1,\naccelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None},\nadafactor=False,\nadam_beta1=0.9,\nadam_beta2=0.999,\nadam_epsilon=1e-08,\nauto_find_batch_size=False,\nbf16=False,\nbf16_full_eval=False,\ndata_seed=None,\ndataloader_drop_last=False,\ndataloader_num_workers=0,\ndataloader_persistent_workers=False,\ndataloader_pin_memory=True,\ndataloader_prefetch_factor=None,\nddp_backend=None,\nddp_broadcast_buffers=None,\nddp_bucket_cap_mb=None,\nddp_find_unused_parameters=None,\nddp_timeout=1800,\ndebug=[],\ndeepspeed=None,\ndisable_tqdm=False,\ndispatch_batches=None,\ndo_eval=True,\ndo_predict=False,\ndo_train=False,\neval_accumulation_steps=None,\neval_delay=0,\neval_do_concat_batches=True,\neval_steps=None,\nevaluation_strategy=epoch,\nfp16=False,\nfp16_backend=auto,\nfp16_full_eval=False,\nfp16_opt_level=O1,\nfsdp=[],\nfsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\nfsdp_min_num_params=0,\nfsdp_transformer_layer_cls_to_wrap=None,\nfull_determinism=False,\ngradient_accumulation_steps=1,\ngradient_checkpointing=False,\ngradient_checkpointing_kwargs=None,\ngreater_is_better=None,\ngroup_by_length=False,\nhalf_precision_backend=auto,\nhub_always_push=False,\nhub_model_id=None,\nhub_private_repo=False,\nhub_strategy=every_save,\nhub_token=<HUB_TOKEN>,\nignore_data_skip=False,\ninclude_inputs_for_metrics=False,\ninclude_num_input_tokens_seen=False,\ninclude_tokens_per_second=False,\njit_mode_eval=False,\nlabel_names=None,\nlabel_smoothing_factor=0.0,\nlearning_rate=2e-05,\nlength_column_name=length,\nload_best_model_at_end=False,\nlocal_rank=0,\nlog_level=passive,\nlog_level_replica=warning,\nlog_on_each_node=True,\nlogging_dir=test_ner/runs/Apr23_07-37-23_08c024d19f9a,\nlogging_first_step=False,\nlogging_nan_inf_filter=True,\nlogging_steps=500,\nlogging_strategy=steps,\nlr_scheduler_kwargs={},\nlr_scheduler_type=linear,\nmax_grad_norm=1.0,\nmax_steps=-1,\nmetric_for_best_model=None,\nmp_parameters=,\nneftune_noise_alpha=None,\nno_cuda=False,\nnum_train_epochs=5,\noptim=adamw_torch,\noptim_args=None,\noptim_target_modules=None,\noutput_dir=test_ner,\noverwrite_output_dir=False,\npast_index=-1,\nper_device_eval_batch_size=16,\nper_device_train_batch_size=16,\nprediction_loss_only=False,\npush_to_hub=False,\npush_to_hub_model_id=None,\npush_to_hub_organization=None,\npush_to_hub_token=<PUSH_TO_HUB_TOKEN>,\nray_scope=last,\nremove_unused_columns=True,\nreport_to=['tensorboard', 'wandb'],\nresume_from_checkpoint=None,\nrun_name=test_ner,\nsave_on_each_node=False,\nsave_only_model=False,\nsave_safetensors=True,\nsave_steps=500,\nsave_strategy=steps,\nsave_total_limit=None,\nseed=42,\nskip_memory_metrics=True,\nsplit_batches=None,\ntf32=None,\ntorch_compile=False,\ntorch_compile_backend=None,\ntorch_compile_mode=None,\ntorchdynamo=None,\ntpu_metrics_debug=False,\ntpu_num_cores=None,\nuse_cpu=False,\nuse_ipex=False,\nuse_legacy_prediction_loop=False,\nuse_mps_device=False,\nwarmup_ratio=0.0,\nwarmup_steps=0,\nweight_decay=0.01,\n)"},"metadata":{}}]},{"cell_type":"code","source":"tokenized_dataset","metadata":{"execution":{"iopub.status.busy":"2024-04-23T07:36:42.675739Z","iopub.execute_input":"2024-04-23T07:36:42.676124Z","iopub.status.idle":"2024-04-23T07:36:42.682174Z","shell.execute_reply.started":"2024-04-23T07:36:42.676098Z","shell.execute_reply":"2024-04-23T07:36:42.681156Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n        num_rows: 14041\n    })\n    validation: Dataset({\n        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n        num_rows: 3250\n    })\n    test: Dataset({\n        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n        num_rows: 3453\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"!pip install seqeval","metadata":{"execution":{"iopub.status.busy":"2024-04-23T07:36:44.001599Z","iopub.execute_input":"2024-04-23T07:36:44.002517Z","iopub.status.idle":"2024-04-23T07:37:01.739777Z","shell.execute_reply.started":"2024-04-23T07:36:44.002482Z","shell.execute_reply":"2024-04-23T07:37:01.738621Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting seqeval\n  Downloading seqeval-1.2.2.tar.gz (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from seqeval) (1.26.4)\nRequirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.10/site-packages (from seqeval) (1.2.2)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (1.11.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (1.4.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (3.2.0)\nBuilding wheels for collected packages: seqeval\n  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=c7ec034e663ec168aa92fa97197d41a6151d68dc681d2036b93c8f2ef687cff0\n  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\nSuccessfully built seqeval\nInstalling collected packages: seqeval\nSuccessfully installed seqeval-1.2.2\n","output_type":"stream"}]},{"cell_type":"code","source":"metric = load_metric('seqeval')","metadata":{"execution":{"iopub.status.busy":"2024-04-23T07:37:01.741900Z","iopub.execute_input":"2024-04-23T07:37:01.742859Z","iopub.status.idle":"2024-04-23T07:37:02.248781Z","shell.execute_reply.started":"2024-04-23T07:37:01.742828Z","shell.execute_reply":"2024-04-23T07:37:02.248027Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_34/10876318.py:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n  metric = load_metric('seqeval')\n/opt/conda/lib/python3.10/site-packages/datasets/load.py:756: FutureWarning: The repository for seqeval contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/seqeval/seqeval.py\nYou can avoid this message in future by passing the argument `trust_remote_code=True`.\nPassing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/2.47k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"117db3ee765541d281e52719f4d5f700"}},"metadata":{}}]},{"cell_type":"code","source":"label_list = dataset['train'].features['ner_tags'].feature.names\nlabel_list","metadata":{"execution":{"iopub.status.busy":"2024-04-23T07:37:02.249663Z","iopub.execute_input":"2024-04-23T07:37:02.249920Z","iopub.status.idle":"2024-04-23T07:37:02.256865Z","shell.execute_reply.started":"2024-04-23T07:37:02.249896Z","shell.execute_reply":"2024-04-23T07:37:02.256057Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']"},"metadata":{}}]},{"cell_type":"code","source":"example = dataset['train'][0]\nlabels = [label_list[i] for i in example['ner_tags']]","metadata":{"execution":{"iopub.status.busy":"2024-04-23T07:37:04.100084Z","iopub.execute_input":"2024-04-23T07:37:04.100814Z","iopub.status.idle":"2024-04-23T07:37:04.106172Z","shell.execute_reply.started":"2024-04-23T07:37:04.100786Z","shell.execute_reply":"2024-04-23T07:37:04.105039Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"example['ner_tags'],labels ","metadata":{"execution":{"iopub.status.busy":"2024-04-23T07:37:05.753222Z","iopub.execute_input":"2024-04-23T07:37:05.753913Z","iopub.status.idle":"2024-04-23T07:37:05.760392Z","shell.execute_reply.started":"2024-04-23T07:37:05.753882Z","shell.execute_reply":"2024-04-23T07:37:05.759345Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"([3, 0, 7, 0, 0, 0, 7, 0, 0],\n ['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O'])"},"metadata":{}}]},{"cell_type":"code","source":"def compute_metrics(eval_preds):\n    pred_logits, labels = eval_preds\n\n    pred_logits = np.argmax(pred_logits, axis=2)\n    # the logits and the probabilities are in the same order,\n    # so we don’t need to apply the softmax\n\n    # We remove all the values where the label is -100\n    predictions = [\n        [label_list[eval_preds] for (eval_preds, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(pred_logits, labels)\n    ]\n\n    true_labels = [\n      [label_list[l] for (eval_preds, l) in zip(prediction, label) if l != -100]\n       for prediction, label in zip(pred_logits, labels)\n   ]\n    results = metric.compute(predictions=predictions, references=true_labels)\n\n    return {\n          \"precision\": results[\"overall_precision\"],\n          \"recall\": results[\"overall_recall\"],\n          \"f1\": results[\"overall_f1\"],\n          \"accuracy\": results[\"overall_accuracy\"],\n  }","metadata":{"execution":{"iopub.status.busy":"2024-04-23T07:37:28.253064Z","iopub.execute_input":"2024-04-23T07:37:28.253934Z","iopub.status.idle":"2024-04-23T07:37:28.261837Z","shell.execute_reply.started":"2024-04-23T07:37:28.253898Z","shell.execute_reply":"2024-04-23T07:37:28.260543Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"data_collator=DataCollatorForTokenClassification(tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-04-23T07:37:29.001354Z","iopub.execute_input":"2024-04-23T07:37:29.002078Z","iopub.status.idle":"2024-04-23T07:37:29.006131Z","shell.execute_reply.started":"2024-04-23T07:37:29.002047Z","shell.execute_reply":"2024-04-23T07:37:29.005082Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"train = Trainer(model,\n       argumnet,\n       train_dataset = tokenized_dataset['train'],\n       eval_dataset =  tokenized_dataset['validation'],\n       data_collator = data_collator,\n       tokenizer = tokenizer,\n       compute_metrics = compute_metrics)","metadata":{"execution":{"iopub.status.busy":"2024-04-23T07:39:43.921916Z","iopub.execute_input":"2024-04-23T07:39:43.922796Z","iopub.status.idle":"2024-04-23T07:39:43.935875Z","shell.execute_reply.started":"2024-04-23T07:39:43.922765Z","shell.execute_reply":"2024-04-23T07:39:43.934880Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"train.train()","metadata":{"execution":{"iopub.status.busy":"2024-04-23T07:39:53.010461Z","iopub.execute_input":"2024-04-23T07:39:53.011336Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}